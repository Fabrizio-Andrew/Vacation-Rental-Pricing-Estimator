{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import feather # pip install feather-format\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import geopandas as gpd\n",
    "import ast\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "import geopy.distance\n",
    "%matplotlib inline\n",
    "## Some utility functions\n",
    "def percentToInt(percentString):\n",
    "    try:\n",
    "        return int(percentString.rstrip(\"%\"))\n",
    "    except:\n",
    "        return None\n",
    "def trueFalseToBinary(tfstring):\n",
    "    return 1 if tfstring=='t' else '0'\n",
    "def stringListToList(stringList):\n",
    "    return ast.literal_eval(stringList)\n",
    "def stringListToCount(stringList):\n",
    "    return len(ast.literal_eval(stringList))\n",
    "def euclideanDistance(lat1, long1, lat2, long2):\n",
    "    return ((long2-long1)**2 + (lat2-lat1)**2)**(0.5)\n",
    "    \n",
    "reviews_data_path = \"feather/reviews.feather\"\n",
    "listings_data_path = \"feather/listings.feather\"\n",
    "calendar_data_path = \"feather/calendar.feather\"\n",
    "sites_data_path = \"data/sites_boston.csv\"\n",
    "\n",
    "reviews_data = pd.read_feather(reviews_data_path)\n",
    "listings_data = pd.read_feather(listings_data_path)\n",
    "calendar_data = pd.read_feather(calendar_data_path)\n",
    "sites_data = pd.read_csv(sites_data_path)\n",
    "\n",
    "# subway data\n",
    "# https://api-v3.mbta.com/docs/swagger/index.html#/Stop\n",
    "# holidays data\n",
    "# https://pypi.org/project/holidays/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_data = pd.read_csv(\"data/listings.csv\")\n",
    "df_none_null = listings_data.copy(deep = True)\n",
    "reference_date = datetime.datetime(2021,7,12)\n",
    "# adding custom: host_number_of_years\n",
    "host_number_of_years = [(reference_date - datetime.datetime.strptime(i, '%Y-%m-%d')).days/365\n",
    "                        for i in df_none_null['host_since']]\n",
    "df_none_null[\"host_number_of_years\"] = host_number_of_years\n",
    "df_none_null = df_none_null.drop(['host_since'], axis=1)\n",
    "df_none_null['price'] = df_none_null['price'].map(lambda x:float(x[1:].replace(',', '')))\n",
    "df_none_null['host_response_rate'] = df_none_null['host_response_rate'].map(percentToInt)\n",
    "#  host_acceptance_rate:\n",
    "df_none_null['host_acceptance_rate'] = df_none_null['host_acceptance_rate'].map(percentToInt)\n",
    "\n",
    "host_response_time_dummies = pd.get_dummies(df_none_null['host_response_time'],prefix='host_response_time')\n",
    "df_none_null = pd.concat([df_none_null,host_response_time_dummies], axis = 1)\n",
    "df_none_null = df_none_null.drop(['host_response_time'], axis=1)\n",
    "\n",
    "df_none_null['host_verifications'] = df_none_null['host_verifications'].map(stringListToCount).astype('int32')\n",
    "df_none_null['availability_30'] = df_none_null['availability_30']/30.0\n",
    "# \"availability_60\",\n",
    "df_none_null['availability_60'] = df_none_null['availability_60']/60.0\n",
    "# \"availability_90\",\n",
    "df_none_null['availability_90'] = df_none_null['availability_90']/90.0\n",
    "# \"availability_365\", \n",
    "df_none_null['availability_365'] = df_none_null['availability_365']/365.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "landmarks=sites_data[\"Place\"]\n",
    "landmarks_lats = sites_data[\"Latitude\"]\n",
    "landmarks_longs = sites_data[\"Longitude\"]\n",
    "\n",
    "# pending further considerations\n",
    "def RMeanSquared(list_distances):\n",
    "    output = []\n",
    "    for i in list_distances:\n",
    "        output.append(i**2)\n",
    "    return np.sqrt(np.mean(output))\n",
    "\n",
    "def SortAndGetTop(list_distances, LargeFirst=False, n=5):\n",
    "    list_distances.sort(reverse=LargeFirst)\n",
    "    return list_distances[0:n]\n",
    "\n",
    "result = []\n",
    "\n",
    "for i in range(len(df_none_null.index)):\n",
    "    dist_to_each_landmark = []\n",
    "    lat2,long2 =df_none_null.iloc[i].latitude,df_none_null.iloc[i].longitude\n",
    "    for j, landmark in enumerate(landmarks):\n",
    "        # euclideanDistance(lat1, long1, lat2, long2)\n",
    "        lat1,long1 = landmarks_lats[j],landmarks_longs[j]\n",
    "        # dist_to_each_landmark.append(euclideanDistance(lat1, long1, lat2, long2))\n",
    "        dist_to_each_landmark.append(geopy.distance.distance((lat1, long1),(lat2, long2)).km)\n",
    "    # result.append(min(dist_to_each_landmark))\n",
    "    result.append(RMeanSquared(SortAndGetTop(dist_to_each_landmark)))\n",
    "\n",
    "df_none_null[\"closeness_to_landmark\"] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import simplejson as json\n",
    "subway_data_path = \"data/transport/subway.json\"\n",
    "# attributes.name .longitude .latitude .description\n",
    "# id\n",
    "# within attributes.description , there is Red Blue Green Orange Line info\n",
    "\n",
    "subway_names = []\n",
    "subway_lines = []\n",
    "subway_lats = []\n",
    "subway_longs = []\n",
    "with open(subway_data_path) as f:\n",
    "    subway_data = json.load(f)['data']\n",
    "    for i in subway_data:\n",
    "        subway_names.append(i['attributes']['name'])\n",
    "        subway_lats.append(i['attributes']['latitude'])\n",
    "        subway_longs.append(i['attributes']['longitude'])\n",
    "        if(\"Red Line\" in i['attributes']['description']):\n",
    "            subway_lines.append(\"r\")\n",
    "            # print(i['attributes']['description'])\n",
    "        elif(\"Blue Line\" in i['attributes']['description']):\n",
    "            subway_lines.append(\"b\")\n",
    "        elif(\"Orange Line\" in i['attributes']['description']):\n",
    "            subway_lines.append(\"o\")\n",
    "        else:\n",
    "            subway_lines.append(None)\n",
    "\n",
    "\n",
    "result = []\n",
    "\n",
    "for i in range(len(df_none_null.index)):\n",
    "    dist_to_each_subway = []\n",
    "    for j, subway in enumerate(subway_names):\n",
    "        # euclideanDistance(lat1, long1, lat2, long2)\n",
    "        lat1,long1 = subway_lats[j],subway_longs[j]\n",
    "        lat2,long2 =df_none_null.iloc[i].latitude,df_none_null.iloc[i].longitude\n",
    "        dist_to_each_subway.append(geopy.distance.distance((lat1, long1),(lat2, long2)).km)\n",
    "    # result.append(min(dist_to_each_subway))\n",
    "    result.append(RMeanSquared(SortAndGetTop(dist_to_each_subway)))\n",
    "\n",
    "df_none_null[\"closeness_to_subway\"] = result\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_none_null.to_csv(\"data/listings_postgres.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_to_float(price):\n",
    "    try:\n",
    "        if price == \"\":\n",
    "            return 0\n",
    "        else:\n",
    "            return float(price[1:].replace(',', ''))\n",
    "    except:\n",
    "        return 0\n",
    "calendar_data = pd.read_csv(\n",
    "    \"data/calendar.csv\"\n",
    ")\n",
    "calendar_data['price'] = calendar_data['price'].map(price_to_float)\n",
    "calendar_data['adjusted_price']= calendar_data['adjusted_price'].map(price_to_float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_data.to_csv(\"data/calendar_postgres.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac4cc79bc1f1a59eb03ea5f2271fa031b0cad04395b546dc321eab6c66d93aea"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('lab4': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
